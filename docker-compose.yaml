version: "3.9"
services:
  de_psql:
    image: postgres:14-alpine
    container_name: de_psql
    hostname: de_psql
    volumes:
      - postgres_data:/var/lib/postgresql/data
      - ./pg_hba.conf:/tmp/pg_hba.conf
      # - ./load_dataset:/tmp/load_dataset
    command: ["postgres", "-c", "hba_file=/tmp/pg_hba.conf"]
    expose:
      - "5432"
    ports:
      - "5432:5432"
    env_file: .env
    networks:
      - de_network

  de_dagster_dagit:
    build:
      context: ./dagster
      dockerfile: Dockerfile
    entrypoint:
      - dagit
      - -h
      - "0.0.0.0"
      - -p
      - "3001"
      - -w
      - workspace.yaml
    container_name: de_dagster_dagit
    ports:
      - "3001:3001"
    volumes:
      - /var/run/docker.sock:/var/run/docker.sock
      - ./dagster_home:/opt/dagster/dagster_home
    env_file:
      - .env
    networks:
      - de_network
    depends_on:
      - de_psql

  de_dagster_daemon:
    build:
      context: ./dagster
      dockerfile: Dockerfile
    entrypoint:
      - dagster-daemon
      - run
    container_name: de_dagster_daemon
    volumes:
      - /var/run/docker.sock:/var/run/docker.sock
      - ./dagster_home:/opt/dagster/dagster_home
    env_file:
      - .env
    networks:
      - de_network
    depends_on:
      - de_psql

  etl_pipeline:
    build:
      context: ./etl_pipeline
      dockerfile: Dockerfile
    container_name: etl_pipeline
    image: etl_pipeline:latest
    user: root
    volumes:
      - ./etl_pipeline:/opt/dagster/app/etl_pipeline
      # - ./etl_pipeline/spark-defaults.conf:/usr/local/spark/conf/spark-defaults.conf
    env_file:
      - .env
    expose:
      - "4000"
    networks:
      - de_network

networks:
  de_network:
    driver: bridge
    name: de_network

volumes:
  postgres_data: {}
